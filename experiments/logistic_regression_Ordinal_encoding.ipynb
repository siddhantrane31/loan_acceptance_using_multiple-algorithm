{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06c16379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, confusion_matrix,\n",
    "    precision_score, recall_score\n",
    ")\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ea2817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"C:/ML_AI/loan/loan_acceptance_using_multiple-algorithm/data/ordinal_encode/train_processed_data.csv\")\n",
    "\n",
    "df2= pd.read_csv(\"C:/ML_AI/loan/loan_acceptance_using_multiple-algorithm/data/ordinal_encode/test_processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf71937",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=df1.drop(labels=[\"loan_status\"],axis=1)\n",
    "ytrain=df1[[\"loan_status\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9c5ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest=df2.drop(labels=[\"loan_status\"],axis=1)\n",
    "ytest=df2[[\"loan_status\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd86db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy=1.0, random_state=42)  \n",
    "X_res, y_res = rus.fit_resample(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "389a3a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 756 candidates, totalling 3780 fits\n",
      "Best Parameters: {'C': 0.01, 'l1_ratio': 0, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score: 0.8092573663831327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "1890 fits failed out of a total of 3780.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "315 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "315 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 72, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "315 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "133 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "206 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "409 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "62 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "77 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "58 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [0.         0.66666665        nan 0.78529789 0.79465228 0.79471095\n",
      "        nan 0.79465228        nan        nan        nan        nan\n",
      " 0.         0.66666665        nan 0.78529789 0.79465228 0.79471095\n",
      "        nan 0.79465228        nan        nan        nan        nan\n",
      " 0.         0.66666665        nan 0.78529789 0.79465228 0.79471095\n",
      "        nan 0.79465228        nan        nan        nan        nan\n",
      " 0.         0.66666665        nan 0.78529789 0.79465228 0.79471095\n",
      "        nan 0.                nan        nan        nan        nan\n",
      " 0.         0.66666665        nan 0.78529789 0.79465228 0.79471095\n",
      "        nan 0.                nan        nan        nan        nan\n",
      " 0.         0.66666665        nan 0.78529789 0.79465228 0.79471095\n",
      "        nan 0.                nan        nan        nan        nan\n",
      " 0.         0.66666665        nan 0.78529789 0.79465228 0.79471095\n",
      "        nan 0.66666665        nan        nan        nan        nan\n",
      " 0.         0.66666665        nan 0.78529789 0.79465228 0.79471095\n",
      "        nan 0.66666665        nan        nan        nan        nan\n",
      " 0.         0.66666665        nan 0.78529789 0.79465228 0.79471095\n",
      "        nan 0.66666665        nan        nan        nan        nan\n",
      " 0.78826874 0.80405803        nan 0.80019472 0.80157429 0.80154531\n",
      "        nan 0.80157429        nan        nan        nan        nan\n",
      " 0.78826874 0.80405803        nan 0.80019472 0.80157429 0.80154531\n",
      "        nan 0.80157429        nan        nan        nan        nan\n",
      " 0.78826874 0.80405803        nan 0.80019472 0.80157429 0.80154531\n",
      "        nan 0.80157429        nan        nan        nan        nan\n",
      " 0.78826874 0.80405803        nan 0.80019472 0.80157429 0.80154531\n",
      "        nan 0.80222307        nan        nan        nan        nan\n",
      " 0.78826874 0.80405803        nan 0.80019472 0.80157429 0.80154531\n",
      "        nan 0.80222307        nan        nan        nan        nan\n",
      " 0.78826874 0.80405803        nan 0.80019472 0.80157429 0.80154531\n",
      "        nan 0.80222307        nan        nan        nan        nan\n",
      " 0.78826874 0.80405803        nan 0.80019472 0.80157429 0.80154531\n",
      "        nan 0.80405803        nan        nan        nan        nan\n",
      " 0.78826874 0.80405803        nan 0.80019472 0.80157429 0.80154531\n",
      "        nan 0.80405803        nan        nan        nan        nan\n",
      " 0.78826874 0.80405803        nan 0.80019472 0.80157429 0.80154531\n",
      "        nan 0.80405803        nan        nan        nan        nan\n",
      " 0.80925737 0.80862582        nan 0.8072861  0.80708331 0.80699458\n",
      "        nan 0.80708331        nan        nan        nan        nan\n",
      " 0.80925737 0.80862582        nan 0.8072861  0.80708331 0.80699458\n",
      "        nan 0.80708331        nan        nan        nan        nan\n",
      " 0.80925737 0.80862582        nan 0.8072861  0.80708331 0.80699458\n",
      "        nan 0.80708331        nan        nan        nan        nan\n",
      " 0.80925737 0.80862582        nan 0.8072861  0.80708331 0.80699458\n",
      "        nan 0.8072342         nan        nan        nan        nan\n",
      " 0.80925737 0.80862582        nan 0.8072861  0.80708331 0.80699458\n",
      "        nan 0.8072342         nan        nan        nan        nan\n",
      " 0.80925737 0.80862582        nan 0.8072861  0.80708331 0.80699458\n",
      "        nan 0.8072342         nan        nan        nan        nan\n",
      " 0.80925737 0.80862582        nan 0.8072861  0.80708331 0.80699458\n",
      "        nan 0.80862582        nan        nan        nan        nan\n",
      " 0.80925737 0.80862582        nan 0.8072861  0.80708331 0.80699458\n",
      "        nan 0.80862582        nan        nan        nan        nan\n",
      " 0.80925737 0.80862582        nan 0.8072861  0.80708331 0.80699458\n",
      "        nan 0.80862582        nan        nan        nan        nan\n",
      " 0.80913729 0.80832199        nan 0.80903709 0.80848982 0.80822661\n",
      "        nan 0.80848982        nan        nan        nan        nan\n",
      " 0.80913729 0.80832199        nan 0.80903709 0.80848982 0.80822661\n",
      "        nan 0.80848982        nan        nan        nan        nan\n",
      " 0.80913729 0.80832199        nan 0.80903709 0.80848982 0.80822661\n",
      "        nan 0.80848982        nan        nan        nan        nan\n",
      " 0.80913729 0.80832199        nan 0.80903709 0.80848982 0.80822661\n",
      "        nan 0.80831481        nan        nan        nan        nan\n",
      " 0.80913729 0.80832199        nan 0.80903709 0.80848982 0.80822661\n",
      "        nan 0.80831481        nan        nan        nan        nan\n",
      " 0.80913729 0.80832199        nan 0.80903709 0.80848982 0.80822661\n",
      "        nan 0.80831481        nan        nan        nan        nan\n",
      " 0.80913729 0.80832199        nan 0.80903709 0.80848982 0.80822661\n",
      "        nan 0.80832199        nan        nan        nan        nan\n",
      " 0.80913729 0.80832199        nan 0.80903709 0.80848982 0.80822661\n",
      "        nan 0.80832199        nan        nan        nan        nan\n",
      " 0.80913729 0.80832199        nan 0.80903709 0.80848982 0.80822661\n",
      "        nan 0.80832199        nan        nan        nan        nan\n",
      " 0.80865213 0.80850565        nan 0.80818078 0.80856437 0.8085965\n",
      "        nan 0.80856437        nan        nan        nan        nan\n",
      " 0.80865213 0.80850565        nan 0.80818078 0.80856437 0.8085965\n",
      "        nan 0.80856437        nan        nan        nan        nan\n",
      " 0.80865213 0.80850565        nan 0.80818078 0.80856437 0.8085965\n",
      "        nan 0.80856437        nan        nan        nan        nan\n",
      " 0.80865213 0.80850565        nan 0.80818078 0.80856437 0.8085965\n",
      "        nan 0.80841603        nan        nan        nan        nan\n",
      " 0.80865213 0.80850565        nan 0.80818078 0.80856437 0.8085965\n",
      "        nan 0.80850481        nan        nan        nan        nan\n",
      " 0.80865213 0.80850565        nan 0.80818078 0.80856437 0.8085965\n",
      "        nan 0.80850481        nan        nan        nan        nan\n",
      " 0.80865213 0.80850565        nan 0.80818078 0.80856437 0.8085965\n",
      "        nan 0.80850565        nan        nan        nan        nan\n",
      " 0.80865213 0.80850565        nan 0.80818078 0.80856437 0.8085965\n",
      "        nan 0.80850565        nan        nan        nan        nan\n",
      " 0.80865213 0.80850565        nan 0.80818078 0.80856437 0.8085965\n",
      "        nan 0.80850565        nan        nan        nan        nan\n",
      " 0.80880122 0.80871311        nan 0.80880122 0.80877327 0.80880122\n",
      "        nan 0.80877327        nan        nan        nan        nan\n",
      " 0.80880122 0.80880122        nan 0.80880122 0.80880122 0.80880122\n",
      "        nan 0.80880122        nan        nan        nan        nan\n",
      " 0.80880122 0.80880122        nan 0.80880122 0.80880122 0.80880122\n",
      "        nan 0.80880122        nan        nan        nan        nan\n",
      " 0.80880122 0.80871311        nan 0.80880122 0.80877327 0.80880122\n",
      "        nan 0.80877327        nan        nan        nan        nan\n",
      " 0.80880122 0.80880122        nan 0.80880122 0.80880122 0.80880122\n",
      "        nan 0.80880122        nan        nan        nan        nan\n",
      " 0.80880122 0.80880122        nan 0.80880122 0.80880122 0.80880122\n",
      "        nan 0.80880122        nan        nan        nan        nan\n",
      " 0.80880122 0.80871311        nan 0.80880122 0.80877327 0.80880122\n",
      "        nan 0.80871311        nan        nan        nan        nan\n",
      " 0.80880122 0.80880122        nan 0.80880122 0.80880122 0.80880122\n",
      "        nan 0.80880122        nan        nan        nan        nan\n",
      " 0.80880122 0.80880122        nan 0.80880122 0.80880122 0.80880122\n",
      "        nan 0.80880122        nan        nan        nan        nan\n",
      " 0.80880122 0.80877327        nan 0.80880122 0.80877327 0.80880122\n",
      "        nan 0.80877327        nan        nan        nan        nan\n",
      " 0.80880122 0.80880122        nan 0.80880122 0.80880122 0.80880122\n",
      "        nan 0.80880122        nan        nan        nan        nan\n",
      " 0.80880122 0.80880122        nan 0.80880122 0.80880122 0.80880122\n",
      "        nan 0.80880122        nan        nan        nan        nan\n",
      " 0.80880122 0.80877327        nan 0.80880122 0.80877327 0.80880122\n",
      "        nan 0.80877327        nan        nan        nan        nan\n",
      " 0.80880122 0.80880122        nan 0.80880122 0.80880122 0.80880122\n",
      "        nan 0.80880122        nan        nan        nan        nan\n",
      " 0.80880122 0.80880122        nan 0.80880122 0.80880122 0.80880122\n",
      "        nan 0.80880122        nan        nan        nan        nan\n",
      " 0.80880122 0.80877327        nan 0.80880122 0.80877327 0.80880122\n",
      "        nan 0.80877327        nan        nan        nan        nan\n",
      " 0.80880122 0.80880122        nan 0.80880122 0.80880122 0.80880122\n",
      "        nan 0.80880122        nan        nan        nan        nan\n",
      " 0.80880122 0.80880122        nan 0.80880122 0.80880122 0.80880122\n",
      "        nan 0.80880122        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1221: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs'],\n",
    "    'max_iter': [100, 200, 500],\n",
    "    'l1_ratio': [0, 0.5, 1]  \n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',       \n",
    "    cv=5,               \n",
    "    n_jobs=-1,          \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Best Parameters:\",grid_search.best_params_)\n",
    "print(\"Best Score:\",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c24ff13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "2025/11/12 14:49:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/12 14:49:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run logged: C=0.01, penalty=l1, solver=liblinear\n",
      "Train: Acc=0.894, ROC=0.881, Prec=0.740, Rec=0.397\n",
      "Test : Acc=0.898, ROC=0.880, Prec=0.751, Rec=0.408\n"
     ]
    }
   ],
   "source": [
    "Best_Parameters={'C': 0.01, 'l1_ratio': 0, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "mlflow.set_tracking_uri(\"file:///C:/ML_AI/loan/loan_acceptance_using_multiple-algorithm/mlruns\")\n",
    "mlflow.set_experiment(\"loan_acceptance_logreg\")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Ordinal_encoding_logistic_regression\"):\n",
    "\n",
    "\n",
    "    mlflow.log_param(\"C\", Best_Parameters[\"C\"])\n",
    "    mlflow.log_param(\"penalty\", Best_Parameters[\"penalty\"])\n",
    "    mlflow.log_param(\"solver\", Best_Parameters[\"solver\"])\n",
    "    mlflow.log_param(\"max_iter\", Best_Parameters[\"max_iter\"])\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        C=Best_Parameters[\"C\"],\n",
    "        penalty=Best_Parameters[\"penalty\"],\n",
    "        solver=Best_Parameters[\"solver\"],\n",
    "        max_iter=Best_Parameters[\"max_iter\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(xtrain, ytrain)\n",
    "\n",
    "    y_pred_train = model.predict(xtrain)\n",
    "    y_prob_train = model.predict_proba(xtrain)[:, 1]\n",
    "\n",
    "    acc_train = accuracy_score(ytrain, y_pred_train)\n",
    "    roc_train = roc_auc_score(ytrain, y_prob_train)\n",
    "    prec_train = precision_score(ytrain, y_pred_train)\n",
    "    rec_train = recall_score(ytrain, y_pred_train)\n",
    "\n",
    "    y_pred_test = model.predict(xtest)\n",
    "    y_prob_test = model.predict_proba(xtest)[:, 1]\n",
    "\n",
    "    acc_test = accuracy_score(ytest, y_pred_test)\n",
    "    roc_test = roc_auc_score(ytest, y_prob_test)\n",
    "    prec_test = precision_score(ytest, y_pred_test)\n",
    "    rec_test = recall_score(ytest, y_pred_test)\n",
    "\n",
    "    mlflow.log_metric(\"train_accuracy\", acc_train)\n",
    "    mlflow.log_metric(\"train_roc_auc\", roc_train)\n",
    "    mlflow.log_metric(\"train_precision\", prec_train)\n",
    "    mlflow.log_metric(\"train_recall\", rec_train)\n",
    "\n",
    "    mlflow.log_metric(\"test_accuracy\", acc_test)\n",
    "    mlflow.log_metric(\"test_roc_auc\", roc_test)\n",
    "    mlflow.log_metric(\"test_precision\", prec_test)\n",
    "    mlflow.log_metric(\"test_recall\", rec_test)\n",
    "\n",
    "    import os\n",
    "    os.makedirs(\"metrics\", exist_ok=True)\n",
    "\n",
    "    cm_train = confusion_matrix(ytrain, y_pred_train)\n",
    "    cm_test = confusion_matrix(ytest, y_pred_test)\n",
    "\n",
    "    np.save(\"metrics/confusion_matrix_train.npy\", cm_train)\n",
    "    np.save(\"metrics/confusion_matrix_test.npy\", cm_test)\n",
    "\n",
    "    mlflow.log_artifact(\"metrics/confusion_matrix_train.npy\", artifact_path=\"metrics\")\n",
    "    mlflow.log_artifact(\"metrics/confusion_matrix_test.npy\", artifact_path=\"metrics\")\n",
    "\n",
    "    mlflow.sklearn.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "    print(f\"Run logged: C={Best_Parameters['C']}, penalty={Best_Parameters['penalty']}, solver={Best_Parameters['solver']}\")\n",
    "    print(f\"Train: Acc={acc_train:.3f}, ROC={roc_train:.3f}, Prec={prec_train:.3f}, Rec={rec_train:.3f}\")\n",
    "    print(f\"Test : Acc={acc_test:.3f}, ROC={roc_test:.3f}, Prec={prec_test:.3f}, Rec={rec_test:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
