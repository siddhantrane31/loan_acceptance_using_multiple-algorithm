{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f3b3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, confusion_matrix,\n",
    "    precision_score, recall_score\n",
    ")\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38475268",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = pd.read_csv(\"C:/ML_AI/loan/loan_acceptance_using_multiple-algorithm/data/one_hot_encode/train_processed_data.csv\")\n",
    "\n",
    "\n",
    "\n",
    "df2 = pd.read_csv(\"C:/ML_AI/loan/loan_acceptance_using_multiple-algorithm/data/one_hot_encode/test_processed_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fdbe33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__person_age</th>\n",
       "      <th>num__person_income</th>\n",
       "      <th>num__person_emp_length</th>\n",
       "      <th>num__loan_amnt</th>\n",
       "      <th>num__loan_int_rate</th>\n",
       "      <th>num__loan_percent_income</th>\n",
       "      <th>num__cb_person_cred_hist_length</th>\n",
       "      <th>cat__person_home_ownership_OTHER</th>\n",
       "      <th>cat__person_home_ownership_OWN</th>\n",
       "      <th>cat__person_home_ownership_RENT</th>\n",
       "      <th>...</th>\n",
       "      <th>cat__loan_intent_PERSONAL</th>\n",
       "      <th>cat__loan_intent_VENTURE</th>\n",
       "      <th>cat__loan_grade_B</th>\n",
       "      <th>cat__loan_grade_C</th>\n",
       "      <th>cat__loan_grade_D</th>\n",
       "      <th>cat__loan_grade_E</th>\n",
       "      <th>cat__loan_grade_F</th>\n",
       "      <th>cat__loan_grade_G</th>\n",
       "      <th>cat__cb_person_default_on_file_Y</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.397825</td>\n",
       "      <td>-0.366415</td>\n",
       "      <td>-1.182680</td>\n",
       "      <td>-0.359703</td>\n",
       "      <td>1.042717</td>\n",
       "      <td>-0.205762</td>\n",
       "      <td>2.274652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.091851</td>\n",
       "      <td>-0.542752</td>\n",
       "      <td>-0.429373</td>\n",
       "      <td>-0.755235</td>\n",
       "      <td>0.321836</td>\n",
       "      <td>-0.424086</td>\n",
       "      <td>0.787969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.422891</td>\n",
       "      <td>0.152225</td>\n",
       "      <td>-1.182680</td>\n",
       "      <td>-0.215873</td>\n",
       "      <td>-0.922425</td>\n",
       "      <td>-0.533248</td>\n",
       "      <td>-0.698714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.894383</td>\n",
       "      <td>0.281885</td>\n",
       "      <td>-0.680475</td>\n",
       "      <td>1.042639</td>\n",
       "      <td>-1.363513</td>\n",
       "      <td>0.449211</td>\n",
       "      <td>1.283530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.919449</td>\n",
       "      <td>-0.480515</td>\n",
       "      <td>0.072832</td>\n",
       "      <td>-0.935022</td>\n",
       "      <td>-0.994843</td>\n",
       "      <td>-0.751573</td>\n",
       "      <td>-0.946495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46911</th>\n",
       "      <td>2.887501</td>\n",
       "      <td>-0.107095</td>\n",
       "      <td>-0.931577</td>\n",
       "      <td>1.042639</td>\n",
       "      <td>-0.099501</td>\n",
       "      <td>0.995021</td>\n",
       "      <td>2.522433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46912</th>\n",
       "      <td>-0.919449</td>\n",
       "      <td>0.152225</td>\n",
       "      <td>-0.931577</td>\n",
       "      <td>0.143702</td>\n",
       "      <td>-1.337179</td>\n",
       "      <td>-0.205762</td>\n",
       "      <td>-0.698714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46913</th>\n",
       "      <td>0.735746</td>\n",
       "      <td>0.670864</td>\n",
       "      <td>-1.182680</td>\n",
       "      <td>-1.051884</td>\n",
       "      <td>-1.732183</td>\n",
       "      <td>-1.406545</td>\n",
       "      <td>0.044628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46914</th>\n",
       "      <td>-0.091851</td>\n",
       "      <td>1.189504</td>\n",
       "      <td>-0.680475</td>\n",
       "      <td>-1.114809</td>\n",
       "      <td>0.838632</td>\n",
       "      <td>-1.406545</td>\n",
       "      <td>0.787969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46915</th>\n",
       "      <td>-0.919449</td>\n",
       "      <td>-0.366415</td>\n",
       "      <td>-0.680475</td>\n",
       "      <td>-0.755235</td>\n",
       "      <td>-0.010625</td>\n",
       "      <td>-0.642411</td>\n",
       "      <td>-0.946495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46916 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num__person_age  num__person_income  num__person_emp_length  \\\n",
       "0             1.397825           -0.366415               -1.182680   \n",
       "1            -0.091851           -0.542752               -0.429373   \n",
       "2            -0.422891            0.152225               -1.182680   \n",
       "3             1.894383            0.281885               -0.680475   \n",
       "4            -0.919449           -0.480515                0.072832   \n",
       "...                ...                 ...                     ...   \n",
       "46911         2.887501           -0.107095               -0.931577   \n",
       "46912        -0.919449            0.152225               -0.931577   \n",
       "46913         0.735746            0.670864               -1.182680   \n",
       "46914        -0.091851            1.189504               -0.680475   \n",
       "46915        -0.919449           -0.366415               -0.680475   \n",
       "\n",
       "       num__loan_amnt  num__loan_int_rate  num__loan_percent_income  \\\n",
       "0           -0.359703            1.042717                 -0.205762   \n",
       "1           -0.755235            0.321836                 -0.424086   \n",
       "2           -0.215873           -0.922425                 -0.533248   \n",
       "3            1.042639           -1.363513                  0.449211   \n",
       "4           -0.935022           -0.994843                 -0.751573   \n",
       "...               ...                 ...                       ...   \n",
       "46911        1.042639           -0.099501                  0.995021   \n",
       "46912        0.143702           -1.337179                 -0.205762   \n",
       "46913       -1.051884           -1.732183                 -1.406545   \n",
       "46914       -1.114809            0.838632                 -1.406545   \n",
       "46915       -0.755235           -0.010625                 -0.642411   \n",
       "\n",
       "       num__cb_person_cred_hist_length  cat__person_home_ownership_OTHER  \\\n",
       "0                             2.274652                               0.0   \n",
       "1                             0.787969                               0.0   \n",
       "2                            -0.698714                               0.0   \n",
       "3                             1.283530                               0.0   \n",
       "4                            -0.946495                               0.0   \n",
       "...                                ...                               ...   \n",
       "46911                         2.522433                               0.0   \n",
       "46912                        -0.698714                               0.0   \n",
       "46913                         0.044628                               0.0   \n",
       "46914                         0.787969                               0.0   \n",
       "46915                        -0.946495                               0.0   \n",
       "\n",
       "       cat__person_home_ownership_OWN  cat__person_home_ownership_RENT  ...  \\\n",
       "0                                 0.0                              1.0  ...   \n",
       "1                                 0.0                              1.0  ...   \n",
       "2                                 0.0                              0.0  ...   \n",
       "3                                 0.0                              0.0  ...   \n",
       "4                                 0.0                              1.0  ...   \n",
       "...                               ...                              ...  ...   \n",
       "46911                             0.0                              1.0  ...   \n",
       "46912                             0.0                              0.0  ...   \n",
       "46913                             0.0                              0.0  ...   \n",
       "46914                             0.0                              0.0  ...   \n",
       "46915                             0.0                              1.0  ...   \n",
       "\n",
       "       cat__loan_intent_PERSONAL  cat__loan_intent_VENTURE  cat__loan_grade_B  \\\n",
       "0                            0.0                       0.0                0.0   \n",
       "1                            0.0                       0.0                0.0   \n",
       "2                            0.0                       0.0                0.0   \n",
       "3                            0.0                       0.0                0.0   \n",
       "4                            0.0                       0.0                0.0   \n",
       "...                          ...                       ...                ...   \n",
       "46911                        0.0                       0.0                1.0   \n",
       "46912                        0.0                       0.0                0.0   \n",
       "46913                        1.0                       0.0                0.0   \n",
       "46914                        0.0                       0.0                0.0   \n",
       "46915                        0.0                       1.0                1.0   \n",
       "\n",
       "       cat__loan_grade_C  cat__loan_grade_D  cat__loan_grade_E  \\\n",
       "0                    1.0                0.0                0.0   \n",
       "1                    1.0                0.0                0.0   \n",
       "2                    0.0                0.0                0.0   \n",
       "3                    0.0                0.0                0.0   \n",
       "4                    0.0                0.0                0.0   \n",
       "...                  ...                ...                ...   \n",
       "46911                0.0                0.0                0.0   \n",
       "46912                0.0                0.0                0.0   \n",
       "46913                0.0                0.0                0.0   \n",
       "46914                1.0                0.0                0.0   \n",
       "46915                0.0                0.0                0.0   \n",
       "\n",
       "       cat__loan_grade_F  cat__loan_grade_G  cat__cb_person_default_on_file_Y  \\\n",
       "0                    0.0                0.0                               1.0   \n",
       "1                    0.0                0.0                               1.0   \n",
       "2                    0.0                0.0                               0.0   \n",
       "3                    0.0                0.0                               0.0   \n",
       "4                    0.0                0.0                               0.0   \n",
       "...                  ...                ...                               ...   \n",
       "46911                0.0                0.0                               0.0   \n",
       "46912                0.0                0.0                               0.0   \n",
       "46913                0.0                0.0                               0.0   \n",
       "46914                0.0                0.0                               1.0   \n",
       "46915                0.0                0.0                               0.0   \n",
       "\n",
       "       loan_status  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "46911            0  \n",
       "46912            0  \n",
       "46913            0  \n",
       "46914            0  \n",
       "46915            0  \n",
       "\n",
       "[46916 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b61dca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=df1.drop(labels=[\"loan_status\"],axis=1)\n",
    "ytrain=df1[[\"loan_status\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9c59c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest=df2.drop(labels=[\"loan_status\"],axis=1)\n",
    "ytest=df2[[\"loan_status\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4be385a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy=1.0, random_state=42)  # 1.0 => equalize counts\n",
    "X_res, y_res = rus.fit_resample(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d06c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3387652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 756 candidates, totalling 3780 fits\n",
      "Best Parameters: {'C': 100, 'l1_ratio': 0, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score: 0.8303848051791626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "1890 fits failed out of a total of 3780.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "315 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "315 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 72, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "315 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "373 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "111 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "121 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "122 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "168 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [0.         0.66666665        nan 0.79213446 0.79687948 0.79696983\n",
      "        nan 0.79687948        nan        nan        nan        nan\n",
      " 0.         0.66666665        nan 0.79213446 0.79687948 0.79696983\n",
      "        nan 0.79687948        nan        nan        nan        nan\n",
      " 0.         0.66666665        nan 0.79213446 0.79687948 0.79696983\n",
      "        nan 0.79687948        nan        nan        nan        nan\n",
      " 0.         0.66666665        nan 0.79213446 0.79687948 0.79696983\n",
      "        nan 0.66666665        nan        nan        nan        nan\n",
      " 0.         0.66666665        nan 0.79213446 0.79687948 0.79696983\n",
      "        nan 0.66666665        nan        nan        nan        nan\n",
      " 0.         0.66666665        nan 0.79213446 0.79687948 0.79696983\n",
      "        nan 0.66666665        nan        nan        nan        nan\n",
      " 0.         0.66666665        nan 0.79213446 0.79687948 0.79696983\n",
      "        nan 0.66666665        nan        nan        nan        nan\n",
      " 0.         0.66666665        nan 0.79213446 0.79687948 0.79696983\n",
      "        nan 0.66666665        nan        nan        nan        nan\n",
      " 0.         0.66666665        nan 0.79213446 0.79687948 0.79696983\n",
      "        nan 0.66666665        nan        nan        nan        nan\n",
      " 0.78157988 0.78156437        nan 0.81648325 0.81535663 0.81529633\n",
      "        nan 0.81535663        nan        nan        nan        nan\n",
      " 0.78157988 0.78156437        nan 0.81648325 0.81535663 0.81529633\n",
      "        nan 0.81535663        nan        nan        nan        nan\n",
      " 0.78157988 0.78156437        nan 0.81648325 0.81535663 0.81529633\n",
      "        nan 0.81535663        nan        nan        nan        nan\n",
      " 0.78157988 0.78156437        nan 0.81648325 0.81535663 0.81529633\n",
      "        nan 0.78804758        nan        nan        nan        nan\n",
      " 0.78157988 0.78156437        nan 0.81648325 0.81535663 0.81529633\n",
      "        nan 0.78804758        nan        nan        nan        nan\n",
      " 0.78157988 0.78156437        nan 0.81648325 0.81535663 0.81529633\n",
      "        nan 0.78804758        nan        nan        nan        nan\n",
      " 0.78157988 0.78156437        nan 0.81648325 0.81535663 0.81529633\n",
      "        nan 0.78156437        nan        nan        nan        nan\n",
      " 0.78157988 0.78156437        nan 0.81648325 0.81535663 0.81529633\n",
      "        nan 0.78156437        nan        nan        nan        nan\n",
      " 0.78157988 0.78156437        nan 0.81648325 0.81535663 0.81529633\n",
      "        nan 0.78156437        nan        nan        nan        nan\n",
      " 0.82247261 0.82004027        nan 0.8273513  0.82790563 0.82805496\n",
      "        nan 0.82790563        nan        nan        nan        nan\n",
      " 0.82247261 0.82004027        nan 0.8273513  0.82790563 0.82805496\n",
      "        nan 0.82790563        nan        nan        nan        nan\n",
      " 0.82247261 0.82004027        nan 0.8273513  0.82790563 0.82805496\n",
      "        nan 0.82790563        nan        nan        nan        nan\n",
      " 0.82247261 0.82004027        nan 0.8273513  0.82790563 0.82805496\n",
      "        nan 0.82507209        nan        nan        nan        nan\n",
      " 0.82247261 0.82004027        nan 0.8273513  0.82790563 0.82805496\n",
      "        nan 0.82507209        nan        nan        nan        nan\n",
      " 0.82247261 0.82004027        nan 0.8273513  0.82790563 0.82805496\n",
      "        nan 0.82507209        nan        nan        nan        nan\n",
      " 0.82247261 0.82004027        nan 0.8273513  0.82790563 0.82805496\n",
      "        nan 0.82004027        nan        nan        nan        nan\n",
      " 0.82247261 0.82004027        nan 0.8273513  0.82790563 0.82805496\n",
      "        nan 0.82004027        nan        nan        nan        nan\n",
      " 0.82247261 0.82004027        nan 0.8273513  0.82790563 0.82805496\n",
      "        nan 0.82004027        nan        nan        nan        nan\n",
      " 0.82938326 0.82925583        nan 0.82892637 0.82922103 0.82942153\n",
      "        nan 0.82922103        nan        nan        nan        nan\n",
      " 0.82938326 0.82935734        nan 0.82892637 0.82929582 0.82942153\n",
      "        nan 0.82929582        nan        nan        nan        nan\n",
      " 0.82938326 0.82995647        nan 0.82892637 0.82935865 0.82942153\n",
      "        nan 0.82935865        nan        nan        nan        nan\n",
      " 0.82938326 0.82925583        nan 0.82892637 0.82922103 0.82942153\n",
      "        nan 0.82963888        nan        nan        nan        nan\n",
      " 0.82938326 0.82935734        nan 0.82892637 0.82929582 0.82942153\n",
      "        nan 0.82964135        nan        nan        nan        nan\n",
      " 0.82938326 0.82995647        nan 0.82892637 0.82935865 0.82942153\n",
      "        nan 0.82946586        nan        nan        nan        nan\n",
      " 0.82938326 0.82925583        nan 0.82892637 0.82922103 0.82942153\n",
      "        nan 0.82925583        nan        nan        nan        nan\n",
      " 0.82938326 0.82935734        nan 0.82892637 0.82929582 0.82942153\n",
      "        nan 0.82935734        nan        nan        nan        nan\n",
      " 0.82938326 0.82995647        nan 0.82892637 0.82935865 0.82942153\n",
      "        nan 0.82995647        nan        nan        nan        nan\n",
      " 0.83026141 0.82948886        nan 0.83001686 0.82955223 0.82999156\n",
      "        nan 0.82955223        nan        nan        nan        nan\n",
      " 0.83026141 0.82950164        nan 0.83001686 0.82977693 0.82999156\n",
      "        nan 0.82977693        nan        nan        nan        nan\n",
      " 0.83026141 0.82941977        nan 0.83001686 0.82962319 0.82999156\n",
      "        nan 0.82962319        nan        nan        nan        nan\n",
      " 0.83026141 0.82948886        nan 0.83001686 0.82955223 0.82999156\n",
      "        nan 0.82946425        nan        nan        nan        nan\n",
      " 0.83026141 0.82950164        nan 0.83001686 0.82977693 0.82999156\n",
      "        nan 0.82971453        nan        nan        nan        nan\n",
      " 0.83026141 0.82941977        nan 0.83001686 0.82962319 0.82999156\n",
      "        nan 0.82955867        nan        nan        nan        nan\n",
      " 0.83026141 0.82948886        nan 0.83001686 0.82955223 0.82999156\n",
      "        nan 0.82948886        nan        nan        nan        nan\n",
      " 0.83026141 0.82950164        nan 0.83001686 0.82977693 0.82999156\n",
      "        nan 0.82950164        nan        nan        nan        nan\n",
      " 0.83026141 0.82941977        nan 0.83001686 0.82962319 0.82999156\n",
      "        nan 0.82941977        nan        nan        nan        nan\n",
      " 0.83029616 0.8299184         nan 0.83020965 0.8299184  0.83036172\n",
      "        nan 0.8299184         nan        nan        nan        nan\n",
      " 0.83029616 0.82938772        nan 0.83020965 0.82938772 0.83036172\n",
      "        nan 0.82938772        nan        nan        nan        nan\n",
      " 0.83029616 0.82981093        nan 0.83020965 0.82981093 0.83036172\n",
      "        nan 0.82981093        nan        nan        nan        nan\n",
      " 0.83029616 0.8299184         nan 0.83020965 0.8299184  0.83036172\n",
      "        nan 0.8299184         nan        nan        nan        nan\n",
      " 0.83029616 0.82938772        nan 0.83020965 0.82938772 0.83036172\n",
      "        nan 0.82938772        nan        nan        nan        nan\n",
      " 0.83029616 0.82981093        nan 0.83020965 0.82981093 0.83036172\n",
      "        nan 0.82981093        nan        nan        nan        nan\n",
      " 0.83029616 0.8299184         nan 0.83020965 0.8299184  0.83036172\n",
      "        nan 0.8299184         nan        nan        nan        nan\n",
      " 0.83029616 0.82938772        nan 0.83020965 0.82938772 0.83036172\n",
      "        nan 0.82938772        nan        nan        nan        nan\n",
      " 0.83029616 0.82981093        nan 0.83020965 0.82981093 0.83036172\n",
      "        nan 0.82981093        nan        nan        nan        nan\n",
      " 0.83038481 0.82985579        nan 0.83038481 0.82985579 0.83011937\n",
      "        nan 0.82985579        nan        nan        nan        nan\n",
      " 0.83038481 0.82938772        nan 0.83038481 0.82938772 0.83011937\n",
      "        nan 0.82938772        nan        nan        nan        nan\n",
      " 0.83038481 0.82974851        nan 0.83038481 0.82974851 0.83011937\n",
      "        nan 0.82974851        nan        nan        nan        nan\n",
      " 0.83038481 0.82985579        nan 0.83038481 0.82985579 0.83011937\n",
      "        nan 0.82985579        nan        nan        nan        nan\n",
      " 0.83038481 0.82938772        nan 0.83038481 0.82938772 0.83011937\n",
      "        nan 0.82938772        nan        nan        nan        nan\n",
      " 0.83038481 0.82974851        nan 0.83038481 0.82974851 0.83011937\n",
      "        nan 0.82974851        nan        nan        nan        nan\n",
      " 0.83038481 0.82985579        nan 0.83038481 0.82985579 0.83011937\n",
      "        nan 0.82985579        nan        nan        nan        nan\n",
      " 0.83038481 0.82938772        nan 0.83038481 0.82938772 0.83011937\n",
      "        nan 0.82938772        nan        nan        nan        nan\n",
      " 0.83038481 0.82974851        nan 0.83038481 0.82974851 0.83011937\n",
      "        nan 0.82974851        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1221: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs'],\n",
    "    'max_iter': [100, 200, 500],\n",
    "    'l1_ratio': [0, 0.5, 1]  \n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',       \n",
    "    cv=5,               \n",
    "    n_jobs=-1,          \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Best Parameters:\",grid_search.best_params_)\n",
    "print(\"Best Score:\",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a82a2701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "2025/11/12 14:37:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/12 14:37:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run logged: C=100, penalty=l1, solver=liblinear\n",
      "Train: Acc=0.913, ROC=0.901, Prec=0.781, Rec=0.540\n",
      "Test : Acc=0.912, ROC=0.905, Prec=0.773, Rec=0.526\n"
     ]
    }
   ],
   "source": [
    "Best_Parameters = {'C': 100, 'l1_ratio': 0, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "\n",
    "mlflow.set_tracking_uri(\"file:///C:/ML_AI/loan/loan_acceptance_using_multiple-algorithm/mlruns\")\n",
    "mlflow.set_experiment(\"loan_acceptance_logreg\")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"logreg_C={Best_Parameters['C']}_{Best_Parameters['penalty']}_{Best_Parameters['solver']}\"):\n",
    "\n",
    "    # log params (use Best_Parameters so variables are defined)\n",
    "    mlflow.log_param(\"C\", Best_Parameters[\"C\"])\n",
    "    mlflow.log_param(\"penalty\", Best_Parameters[\"penalty\"])\n",
    "    mlflow.log_param(\"solver\", Best_Parameters[\"solver\"])\n",
    "    mlflow.log_param(\"max_iter\", Best_Parameters[\"max_iter\"])\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        C=Best_Parameters[\"C\"],\n",
    "        penalty=Best_Parameters[\"penalty\"],\n",
    "        solver=Best_Parameters[\"solver\"],\n",
    "        max_iter=Best_Parameters[\"max_iter\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(xtrain, ytrain)\n",
    "\n",
    "    y_pred_train = model.predict(xtrain)\n",
    "    y_prob_train = model.predict_proba(xtrain)[:, 1]\n",
    "\n",
    "    acc_train = accuracy_score(ytrain, y_pred_train)\n",
    "    roc_train = roc_auc_score(ytrain, y_prob_train)\n",
    "    prec_train = precision_score(ytrain, y_pred_train)\n",
    "    rec_train = recall_score(ytrain, y_pred_train)\n",
    "\n",
    "    y_pred_test = model.predict(xtest)\n",
    "    y_prob_test = model.predict_proba(xtest)[:, 1]\n",
    "\n",
    "    acc_test = accuracy_score(ytest, y_pred_test)\n",
    "    roc_test = roc_auc_score(ytest, y_prob_test)\n",
    "    prec_test = precision_score(ytest, y_pred_test)\n",
    "    rec_test = recall_score(ytest, y_pred_test)\n",
    "\n",
    "    mlflow.log_metric(\"train_accuracy\", acc_train)\n",
    "    mlflow.log_metric(\"train_roc_auc\", roc_train)\n",
    "    mlflow.log_metric(\"train_precision\", prec_train)\n",
    "    mlflow.log_metric(\"train_recall\", rec_train)\n",
    "\n",
    "    mlflow.log_metric(\"test_accuracy\", acc_test)\n",
    "    mlflow.log_metric(\"test_roc_auc\", roc_test)\n",
    "    mlflow.log_metric(\"test_precision\", prec_test)\n",
    "    mlflow.log_metric(\"test_recall\", rec_test)\n",
    "\n",
    "    import os\n",
    "    os.makedirs(\"metrics\", exist_ok=True)\n",
    "\n",
    "    cm_train = confusion_matrix(ytrain, y_pred_train)\n",
    "    cm_test = confusion_matrix(ytest, y_pred_test)\n",
    "\n",
    "    np.save(\"metrics/confusion_matrix_train.npy\", cm_train)\n",
    "    np.save(\"metrics/confusion_matrix_test.npy\", cm_test)\n",
    "\n",
    "    mlflow.log_artifact(\"metrics/confusion_matrix_train.npy\", artifact_path=\"metrics\")\n",
    "    mlflow.log_artifact(\"metrics/confusion_matrix_test.npy\", artifact_path=\"metrics\")\n",
    "\n",
    "    mlflow.sklearn.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "    print(f\"Run logged: C={Best_Parameters['C']}, penalty={Best_Parameters['penalty']}, solver={Best_Parameters['solver']}\")\n",
    "    print(f\"Train: Acc={acc_train:.3f}, ROC={roc_train:.3f}, Prec={prec_train:.3f}, Rec={rec_train:.3f}\")\n",
    "    print(f\"Test : Acc={acc_test:.3f}, ROC={roc_test:.3f}, Prec={prec_test:.3f}, Rec={rec_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98647ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ETLhive\\python\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "2025/11/12 14:26:55 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/12 14:27:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run logged: C=100, penalty=l1, solver=liblinear\n",
      "Train: Acc=0.913, ROC=0.901, Prec=0.781, Rec=0.540\n",
      "Test : Acc=0.912, ROC=0.905, Prec=0.773, Rec=0.526\n"
     ]
    }
   ],
   "source": [
    "# Your best parameters from GridSearch\n",
    "Best_Parameters = {'C': 100, 'l1_ratio': 0, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=f\"logreg_C={Best_Parameters['C']}_{Best_Parameters['penalty']}_{Best_Parameters['solver']}\"):\n",
    "\n",
    " \n",
    "    mlflow.log_param(\"C\", Best_Parameters[\"C\"])\n",
    "    mlflow.log_param(\"penalty\", Best_Parameters[\"penalty\"])\n",
    "    mlflow.log_param(\"solver\", Best_Parameters[\"solver\"])\n",
    "    mlflow.log_param(\"max_iter\", Best_Parameters[\"max_iter\"])\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "   \n",
    "    model = LogisticRegression(\n",
    "        C=Best_Parameters[\"C\"],\n",
    "        penalty=Best_Parameters[\"penalty\"],\n",
    "        solver=Best_Parameters[\"solver\"],\n",
    "        max_iter=Best_Parameters[\"max_iter\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(xtrain, ytrain)\n",
    "\n",
    "\n",
    "    y_pred_train = model.predict(xtrain)\n",
    "    y_prob_train = model.predict_proba(xtrain)[:, 1]\n",
    "\n",
    "    acc_train = accuracy_score(ytrain, y_pred_train)\n",
    "    roc_train = roc_auc_score(ytrain, y_prob_train)\n",
    "    prec_train = precision_score(ytrain, y_pred_train)\n",
    "    rec_train = recall_score(ytrain, y_pred_train)\n",
    "\n",
    "   \n",
    "    y_pred_test = model.predict(xtest)\n",
    "    y_prob_test = model.predict_proba(xtest)[:, 1]\n",
    "\n",
    "    acc_test = accuracy_score(ytest, y_pred_test)\n",
    "    roc_test = roc_auc_score(ytest, y_prob_test)\n",
    "    prec_test = precision_score(ytest, y_pred_test)\n",
    "    rec_test = recall_score(ytest, y_pred_test)\n",
    "\n",
    "  \n",
    "    mlflow.log_metric(\"train_accuracy\", acc_train)\n",
    "    mlflow.log_metric(\"train_roc_auc\", roc_train)\n",
    "    mlflow.log_metric(\"train_precision\", prec_train)\n",
    "    mlflow.log_metric(\"train_recall\", rec_train)\n",
    "\n",
    "    mlflow.log_metric(\"test_accuracy\", acc_test)\n",
    "    mlflow.log_metric(\"test_roc_auc\", roc_test)\n",
    "    mlflow.log_metric(\"test_precision\", prec_test)\n",
    "    mlflow.log_metric(\"test_recall\", rec_test)\n",
    "\n",
    "    \n",
    "    os.makedirs(\"metrics\", exist_ok=True)\n",
    "\n",
    "    cm_train = confusion_matrix(ytrain, y_pred_train)\n",
    "    cm_test = confusion_matrix(ytest, y_pred_test)\n",
    "\n",
    "    np.save(\"metrics/confusion_matrix_train.npy\", cm_train)\n",
    "    np.save(\"metrics/confusion_matrix_test.npy\", cm_test)\n",
    "\n",
    "    mlflow.log_artifact(\"metrics/confusion_matrix_train.npy\", artifact_path=\"metrics\")\n",
    "    mlflow.log_artifact(\"metrics/confusion_matrix_test.npy\", artifact_path=\"metrics\")\n",
    "\n",
    "    \n",
    "    mlflow.sklearn.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "    print(f\"Run logged: C={Best_Parameters['C']}, penalty={Best_Parameters['penalty']}, solver={Best_Parameters['solver']}\")\n",
    "    print(f\"Train: Acc={acc_train:.3f}, ROC={roc_train:.3f}, Prec={prec_train:.3f}, Rec={rec_train:.3f}\")\n",
    "    print(f\"Test : Acc={acc_test:.3f}, ROC={roc_test:.3f}, Prec={prec_test:.3f}, Rec={rec_test:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
